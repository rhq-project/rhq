<?xml version="1.0"?>
<plugin name="hadoop" displayName="hadoopPlugin" description="Monitor Hadoop Clusters" package="org.rhq.plugins.hadoop"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="urn:xmlns:rhq-plugin" xmlns:c="urn:xmlns:rhq-configuration">

  <depends plugin="JMX" useClasses="true"/>

  <!-- NameNode (http://wiki.apache.org/hadoop/NameNode) -->
  <server name="Hadoop NameNode" discovery="HadoopServerDiscovery" class="HadoopServerComponent">
    <plugin-configuration>
      <c:simple-property name="hadoop.home.dir" displayName="Home Directory"/>
      <c:simple-property name="_mainClass" displayName="Main Class" readOnly="true"
        default="org.apache.hadoop.hdfs.server.namenode.NameNode"/>
      <c:simple-property name="logPollingInterval" default="60" description="The interval for log file polling in seconds."/>
    </plugin-configuration>

    <process-scan name="NameNode" query="process|basename|match=^java.*,arg|-Dproc_namenode|match=.*"/>
    
    <operation name="format" displayName="Format dfs" description="Format a new distributed-filesystem.">
      <results><c:simple-property name="operationResult" description="Outcome of formatting the dfs."/></results>
    </operation>
    <operation name="fsck" displayName="Check dfs" description="Runs a HDFS filesystem checking utility.">
      <results><c:simple-property name="operationResult" description="Outcome of checking the dfs."/></results>
    </operation>
    <operation name="ls" displayName="Lists dfs" description="Lists the content of the distributed-filesystem.">
      <results><c:simple-property name="operationResult" description="Outcome of listing the dfs."/></results>
    </operation>

    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:NameDirStatuses" displayName="NameNode Storage"
      dataType="trait" displayType="summary"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:Version" displayName="Version" dataType="trait"
      displayType="summary"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:DeadNodes" displayName="Dead Nodes" dataType="trait"
      displayType="summary"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:DecomNodes" displayName="Decommissioning Nodes"
      dataType="trait" displayType="summary"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:LiveNodes" displayName="Live Nodes" dataType="trait"
      displayType="summary"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:Total" displayName="Capacity Total" units="bytes"
      description="DFS Configured capacitiy"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:Used" displayName="DFS Used" units="bytes"
      description="DFS used" displayType="summary"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:PercentUsed" displayName="DFS Used %"
      description="DFS Used %" displayType="summary"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:NonDfsUsedSpace" displayName="Non DFS Used"
      units="bytes" description="Non DFS used"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:Free" displayName="DFS Capacity Remaining" units="bytes"
      description="DFS remaining"/>
    <!-- jmx returns number from interval (0,100) not from (0,1)  units="percentage" -->
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:PercentRemaining" displayName="DFS Capacity Remaining %"
      description="DFS remaining"/>
    <metric property="Hadoop:service=NameNode,name=NameNodeInfo:TotalBlocks" displayName="Blocks Total" units="none"/>
    <metric property="Hadoop:service=NameNode,name=FSNamesystemState:FilesTotal" displayName="FilesTotal" units="none"/>
    <metric property="Hadoop:service=NameNode,name=FSNamesystemState:PendingReplicationBlocks" displayName="Pending Replication Blocks"
      units="none"/>

    <event name="logEntry" description="an entry in a log file"/>

    <resource-configuration>
      <c:simple-property name="conf/core-site.xml:fs.default.name" displayName="Namenode URI" required="false"/>
      <c:simple-property name="conf/hdfs-site.xml:dfs.name.dir" displayName="Local Namespace and Logs Storage Directory"
        description="Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently." required="false"/>
      <c:simple-property name="conf/hdfs-site.xml:dfs.block.size" displayName="HDFS Block Size"
        description="The default block size for new files. The value is in bytes." required="false"/>
    </resource-configuration>
  </server>

  <server name="Hadoop SecondaryNameNode" discovery="HadoopServerDiscovery" class="HadoopServerComponent">
    <plugin-configuration>
      <c:simple-property name="_mainClass" displayName="Main Class" readOnly="true"
        default="org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode"/>
    </plugin-configuration>
    <process-scan name="SecondaryNameNode" query="process|basename|match=^java.*,arg|-Dproc_secondarynamenode|match=.*"/>
  </server>

  <!-- DataNode (http://wiki.apache.org/hadoop/DataNode) -->
  <server name="DataNode" discovery="HadoopServerDiscovery" class="HadoopServerComponent">
    <plugin-configuration>
      <c:simple-property name="_mainClass" displayName="Main Class" readOnly="true"
        default="org.apache.hadoop.hdfs.server.datanode.DataNode"/>
    </plugin-configuration>

    <process-scan name="DataNode" query="process|basename|match=^java.*,arg|*|match=.*proc_datanode.*"/>

    <metric property="Hadoop:service=DataNode,name=DataNode*:bytes_written" displayName="Bytes Writter"
      measurementType="trendsup"/>
    <metric property="Hadoop:service=DataNode,name=FSDatasetState*:Remaining" displayName="Remaining" units="bytes"/>
    <metric property="Hadoop:service=DataNode,name=FSDatasetState*:Capacity" displayName="Capacity" units="bytes"/>
    <metric property="Hadoop:service=DataNode,name=FSDatasetState*:StorageInfo" dataType="trait" displayType="summary"/>
    <metric property="Hadoop:service=DataNode,name=RpcActivitForPort*:NumOpenConnections" displayName="Number of Open Connections"/>

    <resource-configuration>
      <c:simple-property name="conf/hdfs-site.xml:dfs.data.dir" displayName="Storage Directory"
        description="Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks." required="false"/>
    </resource-configuration>
  </server>

  <!-- JobTracker (http://wiki.apache.org/hadoop/JobTracker) -->
  <server name="Hadoop JobTracker" discovery="HadoopServerDiscovery" class="HadoopServerComponent">
    <plugin-configuration>
      <c:simple-property name="baseObjectName" defaultValue="hadoop:service=JobTracker"/>
      <c:simple-property name="_mainClass" displayName="Main Class" readOnly="true"
        default="org.apache.hadoop.mapred.JobTracker"/>
    </plugin-configuration>

    <process-scan name="JobTracker" query="process|basename|match=^java.*,arg|-Dproc_jobtracker|match=.*"/>

    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:jobs_completed" displayName="Jobs Completed"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:jobs_running" displayName="Jobs Running"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:jobs_preparing" displayName="Jobs Preparing"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:jobs_killed" displayName="Jobs Killed"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:jobs_failed" displayName="Jobs Failed"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:running_maps" displayName="Running Map Tasks"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:running_reduces" displayName="Running Reduce Tasks"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:jobs_submitted" displayName="Total Submissions"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:trackers" displayName="Nodes" displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:occupied_map_slots" displayName="Occupied Map Slots"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:occupied_reduce_slots" displayName="Occupied Reduce Slots"
      description="DFS Configured capacitiy"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:reserved_map_slots" displayName="Reserved Map Slots"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:reserved_reduce_slots" displayName="Reserved Reduce Slots"
      displayType="summary"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:map_slots" displayName="Map Task Capacity"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:reduce_slots" displayName="Reduce Task Capacity"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:trackers_blacklisted" displayName="Blacklisted Nodes"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:trackers_graylisted" displayName="Graylisted Nodes"/>
    <metric property="Hadoop:service=JobTracker,name=JobTrackerMetrics:trackers_decommissioned" displayName="Excluded Nodes"/>

    <resource-configuration>
        <c:simple-property name="conf/mapred-site.xml:mapred.job.tracker" displayName="Host And Port" description="Host or IP and port of JobTracker. host:port pair." required="false"/>
        <c:simple-property name="conf/mapred-site.xml:mapred.system.dir" displayName="System Files Location" description="Path on the HDFS where where the MapReduce framework stores system files e.g. /hadoop/mapred/system/. This is in the default filesystem (HDFS) and must be accessible from both the server and client machines." required="false"/>
        <c:simple-property name="conf/mapred-site.xml:mapred.local.dir" displayName="Data Files Location" description="Comma-separated list of paths on the local filesystem where temporary MapReduce data is written. Multiple paths help spread disk i/o." required="false"/>
        <c:simple-property name="conf/mapred-site.xml:mapred.tasktracker.map.tasks.maximum" displayName="Maximum Map Tasks" description="The maximum number of Map tasks, which are run simultaneously on a given TaskTracker, individually. Defaults to 2 (2 maps and 2 reduces), but vary it depending on your hardware." required="false"/>
        <c:simple-property name="conf/mapred-site.xml:mapred.tasktracker.reduce.tasks.maximum" displayName="Maximum Reduce Tasks" description="The maximum number of Reduce tasks, which are run simultaneously on a given TaskTracker, individually. Defaults to 2 (2 maps and 2 reduces), but vary it depending on your hardware." required="false"/>
        <c:simple-property name="conf/mapred-site.xml:mapred.queue.names" displayName="Job Queues" description="Comma separated list of queues to which jobs can be submitted. The MapReduce system always supports atleast one queue with the name as default. Hence, this parameter's value should always contain the string default. Some job schedulers supported in Hadoop, like the Capacity Scheduler, support multiple queues. If such a scheduler is being used, the list of configured queue names must be specified here. Once queues are defined, users can submit jobs to a queue using the property name mapred.job.queue.name in the job configuration. There could be a separate configuration file for configuring properties of these queues that is managed by the scheduler. Refer to the documentation of the scheduler for information on the same." required="false"/>
    </resource-configuration>
  </server>

  <!-- TaskTracker (http://wiki.apache.org/hadoop/TaskTracker) -->
  <server name="Hadoop TaskTracker" discovery="HadoopServerDiscovery" class="HadoopServerComponent">
    <plugin-configuration>
      <c:simple-property name="_mainClass" displayName="Main Class" readOnly="true"
        default="org.apache.hadoop.mapred.TaskTracker"/>
    </plugin-configuration>

    <process-scan name="TaskTracker" query="process|basename|match=^java.*,arg|-Dproc_tasktracker|match=.*"/>

    <metric property="Hadoop:service=TaskTracker,name=TaskTrackerMetrics:mapTaskSlots" displayName="Map Task Slots"/>
    <metric property="Hadoop:service=TaskTracker,name=TaskTrackerMetrics:reduceTaskSlots" displayName="Reduce Task Slots"/>
    <metric property="Hadoop:service=TaskTracker,name=TaskTrackerMetrics:maps_running" displayName="Running Map Tasks"/>
    <metric property="Hadoop:service=TaskTracker,name=TaskTrackerMetrics:reduces_running" displayName="Running Reduce Tasks"/>
    <metric property="Hadoop:service=TaskTracker,name=TaskTrackerMetrics:tasks_completed" displayName="Tasks Completed"
      displayType="summary"/>
    <metric property="Hadoop:service=TaskTracker,name=RpcDetailedActivityForPort*:done_avg_time" displayName="Task Done Avg. Time"
      displayType="summary"/>

    <metric property="Hadoop:service=TaskTracker,name=TaskTrackerInfo:JobTrackerUrl" displayName="Tasks Completed"
      dataType="trait"/>

  </server>
</plugin>